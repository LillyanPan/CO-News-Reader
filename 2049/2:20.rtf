{\rtf1\ansi\ansicpg1252\cocoartf1348\cocoasubrtf170
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural

\f0\fs24 \cf0 2/20 CS 2049 Lecture\
\
iPhone has 2 cameras\
\
back camera:\
	great quality\
	two tone flash - different intensity, color of flash match light color around you\
Video:\
UIImagePickerController\
	Easy to use - one class\
	delegate protocol - tell one class you are a delegate\
	simple functionality\
AVFoundation\
	LOTs of control\
	Breaks down pipeline into input, output, session management\
	Video editing, use for heavy duty video apps use AVFoundation\
	Fine grained control\
Basics\
	Inputs: camera, microphone\
	Output: video data, audio data, etc\
Capture Basics\
	AVCaptureDeviceInput and AVCaptureVideoDataOutput wrapped in AVCaptureSession\
	create delegate for AVCaptureSession, send data to CALayer display\
	One pipeline just displays video, other runs output though processing pipeline (add goats)\
Layers vs Views\
	UIView: always backed by a layer; at least one layer\
		can receive touch events\
	CA Layer: more lightweight\
\
Bytes Per Row\
	For optimization: uses pixel padding\
CIDetector\
	Can detect: eyes, smile detection\
}